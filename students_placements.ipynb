#students placements
import numpy as np

# Input features (10th %, 12th %, CGPA, and IQ score)
X = np.array([[90, 85, 8.5, 120],
              [80, 90, 7.5, 110],
              [95, 92, 9.0, 130],
              [70, 75, 6.5, 100]])

# Normalize the input features
X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)

# Output labels (0: Not Placed, 1: Placed)
Y = np.array([[0], [1], [1], [0]])

# Initialize weights and bias
W = np.random.randn(4, 1) * 0.01
b = np.zeros((1, 1))

# Learning rate and number of epochs
lr = 0.1
epochs = 1000

# Sigmoid activation function
def sigmoid(x):
    return 1 / (1 + np.exp(-np.clip(x, -100, 100)))

# Derivative of sigmoid function
def sigmoid_derivative(x):
    return x * (1 - x)

# Mean Squared Error (MSE) loss function
def mse_loss(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

# Cross-Entropy loss function
def cross_entropy_loss(y_true, y_pred):
    eps = 1e-15
    y_pred = np.clip(y_pred, eps, 1 - eps)
    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))

# Training loop
for epoch in range(epochs):
    # Forward pass
    z = np.dot(X, W) + b
    A = sigmoid(z)

    # Calculate losses
    loss_mse = mse_loss(Y, A)
    loss_cross_entropy = cross_entropy_loss(Y, A)

    # Backward pass for cross-entropy loss
    d_loss_cross_entropy = (A - Y)
    dW_cross_entropy = np.dot(X.T, d_loss_cross_entropy)
    db_cross_entropy = np.sum(d_loss_cross_entropy, axis=0, keepdims=True)

    # Weight update using cross-entropy loss
    W -= lr * dW_cross_entropy
    b -= lr * db_cross_entropy

    # Print losses at regular intervals
    if epoch % 100 == 0:
        print(f"Epoch {epoch}, MSE Loss: {loss_mse:.4f}, Cross-Entropy Loss: {loss_cross_entropy:.4f}")

# Final predictions
output = sigmoid(np.dot(X, W) + b)
print("\nFinal Predictions:")
print(output.round())

# Accuracy calculation
accuracy = np.mean(output.round() == Y)
print(f"\nAccuracy on training data: {accuracy:.2f}")

# Predict for a new student
new_student = np.array([[85, 80, 8.0, 115]])
new_student = (new_student - np.mean(X + np.zeros((1,4)), axis=0)) / np.std(X, axis=0)
predicted_label = np.round(sigmoid(np.dot(new_student, W) + b))
print(f"\nPredicted label for the new student: {predicted_label[0][0]}")
